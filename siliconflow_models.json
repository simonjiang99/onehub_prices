[
    {
        "modelId": "17885302724",
        "modelName": "deepseek-ai/DeepSeek-R1",
        "mf": "deepseek-ai",
        "desc": "DeepSeek-R1 是一款强化学习（RL）驱动的推理模型，解决了模型中的重复性和可读性问题。在 RL 之前，DeepSeek-R1 引入了冷启动数据，进一步优化了推理性能。它在数学、代码和推理任务中与 OpenAI-o1 表现相当，并且通过精心设计的训练方法，提升了整体效果。",
        "tags": [
            "MoE",
            "671B",
            "64K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DP-%20ST-Logo.svg",
        "publishTime": {
            "seconds": 1737302400
        },
        "size": 671,
        "contextLen": 65536,
        "price": "16",
        "currency": "¥",
        "operationLabel": [
            "华为云昇腾云服务"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "DeepSeek-R1",
        "sort": 4500,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 10000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 15000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 125000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/DeepSeek-R1"
    },
    {
        "modelId": "17885302723",
        "modelName": "deepseek-ai/DeepSeek-V3",
        "mf": "deepseek-ai",
        "desc": "DeepSeek-V3 是一款拥有 6710 亿参数的混合专家（MoE）语言模型，采用多头潜在注意力（MLA）和 DeepSeekMoE 架构，结合无辅助损失的负载平衡策略，优化推理和训练效率。通过在 14.8 万亿高质量tokens上预训练，并进行监督微调和强化学习，DeepSeek-V3 在性能上超越其他开源模型，接近领先闭源模型。",
        "tags": [
            "MoE",
            "671B",
            "64K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DP-%20ST-Logo.svg",
        "publishTime": {
            "seconds": 1735142400
        },
        "size": 671,
        "contextLen": 65536,
        "price": "2",
        "currency": "¥",
        "operationLabel": [
            "华为云昇腾云服务"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "DeepSeek-V3",
        "sort": 4200,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 10000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 15000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 125000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/DeepSeek-V3"
    },
    {
        "modelId": "17885302720",
        "modelName": "deepseek-ai/Janus-Pro-7B",
        "mf": "deepseek-ai",
        "desc": "Janus-Pro 是一款统一理解与生成的多模态大语言模型 (MLLM)，在多模态理解和生成任务中实现了视觉编码的解耦。其架构基于 DeepSeek-LLM-7b-base。在图像生成方面，模型采用来自特定来源的 tokenizer，并支持 16 倍下采样率处理，提升了生成效率和质量。",
        "tags": [
            "7B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DeepSeek.svg",
        "publishTime": {
            "seconds": 1737993600
        },
        "size": 7,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [
            "限免",
            " 上新"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "Janus-Pro-7B",
        "sort": 4100,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ Image",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/Janus-Pro-7B"
    },
    {
        "modelId": "17885302698",
        "modelName": "Qwen/QVQ-72B-Preview",
        "mf": "QVQ",
        "desc": "QVQ-72B-Preview 是由 Qwen 团队开发的专注于视觉推理能力的研究型模型。该模型在多项基准测试中表现突出，在 MMMU 测试中达到了 70.3% 的卓越成绩，在 MathVista 达到 71.4% 的优异表现，展现了其在多学科理解和数学视觉推理方面的卓越能力。作为专门针对视觉推理优化的模型，QVQ-72B-Preview 在复杂场景理解和解决视觉相关的数学问题方面具有独特优势",
        "tags": [
            "72B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1735056000
        },
        "size": 72,
        "contextLen": 32768,
        "price": "9.9",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "QVQ-72B-Preview",
        "sort": 4000,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": true,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/QVQ-72B-Preview"
    },
    {
        "modelId": "17885302679",
        "modelName": "FunAudioLLM/CosyVoice2-0.5B",
        "mf": "FunAudioLLM",
        "desc": "CosyVoice 2 是一个基于大语言模型的流式语音合成模型，采用统一的流式/非流式框架设计。该模型通过有限标量量化（FSQ）来提升语音 token 的编码本利用率，简化了文本到语音的语言模型架构，并开发了支持不同合成场景的分块感知因果流匹配模型。在流式模式下，模型可实现 150ms 的超低延迟，同时保持与非流式模式几乎相同的合成质量。相比 1.0 版本，发音错误率降低了 30%-50%，MOS 评分从 5.4 提升至 5.53，并支持情感和方言的细粒度控制。支持中文（含方言：粤语、四川话、上海话、天津话等）、英文、日语、韩语，支持跨语言和混合语言场景",
        "tags": [
            "多语言",
            "0.5B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/FunAudioLLM.png",
        "publishTime": {
            "seconds": 1734278400
        },
        "size": 1,
        "contextLen": 0,
        "price": "50",
        "currency": "¥",
        "operationLabel": [
            "50% OFF"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "audio",
        "subType": "text-to-speech",
        "DisplayName": "FunAudioLLM/CosyVoice2-0.5B",
        "sort": 3800,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M UTF-8 bytes",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "FunAudioLLM/CosyVoice2-0.5B"
    },
    {
        "modelId": "17885302570",
        "modelName": "deepseek-ai/DeepSeek-V2.5",
        "mf": "deepseek-ai",
        "desc": "DeepSeek-V2.5-1210 是 DeepSeek-V2.5 的升级版本，在多个能力方面都有显著提升。在数学能力方面，其在 MATH-500 基准测试上的表现从 74.8% 提升至 82.8%；在编程方面，LiveCodebench 基准测试的准确率从 29.2% 提升至 34.38%。同时在写作和推理方面也有明显改进。模型支持函数调用、JSON 输出和填充式补全等多种功能",
        "tags": [
            "MoE",
            "236B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DeepSeek.svg",
        "publishTime": {
            "seconds": 1733760000
        },
        "size": -1,
        "contextLen": 32768,
        "price": "1.33",
        "currency": "¥",
        "operationLabel": [
            "1210"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "DeepSeek-V2.5",
        "sort": 3700,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 10000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 15000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 125000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": true,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/DeepSeek-V2.5"
    },
    {
        "modelId": "17885302661",
        "modelName": "meta-llama/Llama-3.3-70B-Instruct",
        "mf": "meta-llama3.3",
        "desc": "Llama 3.3 是 Llama 系列最先进的多语言开源大型语言模型，以极低成本体验媲美 405B 模型的性能。基于 Transformer 结构，并通过监督微调（SFT）和人类反馈强化学习（RLHF）提升有用性和安全性。其指令调优版本专为多语言对话优化，在多项行业基准上表现优于众多开源和封闭聊天模型。知识截止日期为 2023 年 12 月。",
        "tags": [
            "70B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1733414400
        },
        "size": 70,
        "contextLen": 32768,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Llama-3.3-70B-Instruct",
        "sort": 3600,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "meta-llama/Llama-3.3-70B-Instruct"
    },
    {
        "modelId": "17885302703",
        "modelName": "tencent/HunyuanVideo-HD",
        "mf": "hunyuan",
        "desc": "HunyuanVideo 是腾讯推出的开源视频生成基础模型，拥有超过 130 亿参数，是目前最大的开源视频生成模型。该模型采用统一的图像和视频生成架构，集成了数据整理、图像-视频联合模型训练和高效基础设施等关键技术。模型使用多模态大语言模型作为文本编码器，通过 3D VAE 进行空间-时间压缩，并提供提示词重写功能。根据专业人工评估结果，HunyuanVideo 在文本对齐、运动质量和视觉质量等方面的表现优于现有最先进的模型",
        "tags": [
            "13B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/hunyuan.svg",
        "publishTime": {
            "seconds": 1733155200
        },
        "size": 13,
        "contextLen": 0,
        "price": "2.8",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "video",
        "subType": "text-to-video",
        "DisplayName": "HunyuanVideo (HD)",
        "sort": 3600,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 200
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 300
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 500
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 600
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 3000
            }
        ],
        "priceUnit": "/ Video",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "tencent/HunyuanVideo-HD"
    },
    {
        "modelId": "17885302647",
        "modelName": "genmo/mochi-1-preview",
        "mf": "genmo",
        "desc": "Mochi 1 是一个开源的视频生成模型，基于新颖的AsymmDiT架构构建。该模型具有 100 亿参数规模。模型采用非对称编码器-解码器结构，能够将视频压缩至原始大小的 128 倍，具有 8x8 空间压缩和 6 倍时间压缩的特点。在初步评估中，该模型展现出高保真的运动效果和强大的提示遵循能力",
        "tags": [
            "10B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/genmo.png",
        "publishTime": {
            "seconds": 1729526400
        },
        "size": 10,
        "contextLen": 0,
        "price": "2.8",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "video",
        "subType": "text-to-video",
        "DisplayName": "mochi-1-preview",
        "sort": 3500,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 200
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 300
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 500
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 600
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 3000
            }
        ],
        "priceUnit": "/ Video",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "genmo/mochi-1-preview"
    },
    {
        "modelId": "17885302658",
        "modelName": "tencent/HunyuanVideo",
        "mf": "hunyuan",
        "desc": "HunyuanVideo 是腾讯推出的开源视频生成基础模型，拥有超过 130 亿参数，是目前最大的开源视频生成模型。该模型采用统一的图像和视频生成架构，集成了数据整理、图像-视频联合模型训练和高效基础设施等关键技术。模型使用多模态大语言模型作为文本编码器，通过 3D VAE 进行空间-时间压缩，并提供提示词重写功能。根据专业人工评估结果，HunyuanVideo 在文本对齐、运动质量和视觉质量等方面的表现优于现有最先进的模型",
        "tags": [
            "13B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/hunyuan.svg",
        "publishTime": {
            "seconds": 1733155200
        },
        "size": 13,
        "contextLen": 0,
        "price": "0.7",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "video",
        "subType": "text-to-video",
        "DisplayName": "HunyuanVideo",
        "sort": 3500,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 200
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 300
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 500
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 600
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 3000
            }
        ],
        "priceUnit": "/ Video",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "tencent/HunyuanVideo"
    },
    {
        "modelId": "17885302653",
        "modelName": "fishaudio/fish-speech-1.5",
        "mf": "fishaudio",
        "desc": "Fish Speech V1.5 是一款领先的开源文本转语音（TTS）模型。该模型采用创新的 DualAR 架构，包含双自回归变换器设计。它支持多种语言，其中英语和中文各有超过 30 万小时的训练数据，日语超过 10 万小时。在 TTS Arena 的独立评估中，模型表现出色，ELO 评分为 1339。模型在英文单词错误率（WER）和字符错误率（CER）方面分别达到了 3.5% 和 1.2%，中文字符错误率为 1.3%",
        "tags": [
            "多语言"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Fishaudio.svg",
        "publishTime": {
            "seconds": 1732809600
        },
        "size": 0,
        "contextLen": 0,
        "price": "105",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "audio",
        "subType": "text-to-speech",
        "DisplayName": "fish-speech-1.5",
        "sort": 3400,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M UTF-8 bytes",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": true,
        "supportFT": false,
        "targetModelName": "fishaudio/fish-speech-1.5"
    },
    {
        "modelId": "17885302645",
        "modelName": "RVC-Boss/GPT-SoVITS",
        "mf": "RVC-Boss",
        "desc": "GPT-SoVITS 是一个强大的少样本语音转换和文本转语音系统。其最显著的特点是仅需 1 分钟的训练数据即可实现高质量的声音克隆。模型支持零样本 TTS（仅需 5 秒语音样本）和少样本 TTS（使用 1 分钟训练数据进行微调）两种模式。该模型具有跨语言能力，支持英文、日文、韩文、粤语和中文等多种语言的推理，并集成了语音伴奏分离、自动训练集分割、中文 ASR 等实用工具",
        "tags": [],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/RVC.png",
        "publishTime": {
            "seconds": 1722960000
        },
        "size": 0,
        "contextLen": 0,
        "price": "50",
        "currency": "¥",
        "operationLabel": [
            "50% OFF"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "audio",
        "subType": "text-to-speech",
        "DisplayName": "GPT-SoVITS",
        "sort": 3300,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M UTF-8 bytes",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "RVC-Boss/GPT-SoVITS"
    },
    {
        "modelId": "17885302652",
        "modelName": "Qwen/QwQ-32B-Preview",
        "mf": "QwQ",
        "desc": "QwQ-32B-Preview是Qwen 最新的实验性研究模型，专注于提升AI推理能力。通过探索语言混合、递归推理等复杂机制，主要优势包括强大的推理分析能力、数学和编程能力。与此同时，也存在语言切换问题、推理循环、安全性考虑、其他能力方面的差异。",
        "tags": [
            "32B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1732723200
        },
        "size": 32,
        "contextLen": 32768,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [
            "HOT"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "QwQ-32B-Preview",
        "sort": 3300,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/QwQ-32B-Preview"
    },
    {
        "modelId": "17885302623",
        "modelName": "Qwen/Qwen2.5-Coder-32B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-Coder-32B-Instruct 是基于 Qwen2.5 开发的代码特定大语言模型。该模型通过 5.5 万亿 tokens 的训练，在代码生成、代码推理和代码修复方面都取得了显著提升。它是当前最先进的开源代码语言模型，编码能力可与 GPT-4 相媲美。模型不仅增强了编码能力，还保持了在数学和通用能力方面的优势，并支持长文本处理",
        "tags": [
            "Coder",
            "32B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1731254400
        },
        "size": 32,
        "contextLen": 32768,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-Coder-32B-Instruct",
        "sort": 3200,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": true,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2.5-Coder-32B-Instruct"
    },
    {
        "modelId": "17885302608",
        "modelName": "fishaudio/fish-speech-1.4",
        "mf": "fishaudio",
        "desc": "Fish Speech V1.4 是一个先进的文本转语音（TTS）模型，在 70 万小时的多语言音频数据上训练而成。该模型支持 8 种语言，包括约 30 万小时的英语和中文数据，以及各约 2 万小时的德语、日语、法语、西班牙语、韩语和阿拉伯语数据。这使其成为一个强大的多语言语音合成解决方案",
        "tags": [
            "多语言"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Fishaudio.svg",
        "publishTime": {
            "seconds": 1725897600
        },
        "size": 0,
        "contextLen": 0,
        "price": "105",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "audio",
        "subType": "text-to-speech",
        "DisplayName": "fish-speech-1.4",
        "sort": 3000,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M UTF-8 bytes",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": true,
        "supportFT": false,
        "targetModelName": "fishaudio/fish-speech-1.4"
    },
    {
        "modelId": "17885302600",
        "modelName": "stabilityai/stable-diffusion-3-5-large",
        "mf": "stabilityai",
        "desc": "Stable Diffusion 3.5 Large 是 Stable Diffusion 系列中最强大的基础模型，拥有 80 亿参数。该模型具有卓越的图像质量和更好的提示遵循能力，特别适合在 1 兆像素分辨率下进行专业用途",
        "tags": [
            "8B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Stability.svg",
        "publishTime": {
            "seconds": 1729612800
        },
        "size": 8,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "stable-diffusion-3-5-large",
        "sort": 2900,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "stabilityai/stable-diffusion-3-5-large"
    },
    {
        "modelId": "17885302601",
        "modelName": "stabilityai/stable-diffusion-3-5-large-turbo",
        "mf": "stabilityai",
        "desc": "Stable Diffusion 3.5 Large Turbo 是 Stable Diffusion 3.5 Large 的蒸馏版本。该模型能够在仅 4 步内生成高质量图像，并具有出色的提示遵循能力，使其比 Stable Diffusion 3.5 Large 快得多。这种快速生成能力使其成为需要快速图像生成的应用场景的理想选择",
        "tags": [
            "8B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Stability.svg",
        "publishTime": {
            "seconds": 1729612800
        },
        "size": 8,
        "contextLen": 0,
        "price": "0.0032",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "stable-diffusion-3-5-large-turbo",
        "sort": 2890,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "stabilityai/stable-diffusion-3-5-large-turbo"
    },
    {
        "modelId": "17885302654",
        "modelName": "black-forest-labs/FLUX.1-pro",
        "mf": "black-forest-labs",
        "desc": "FLUX.1 [pro] 是 FLUX.1 系列中性能最强大的变体，代表了文本到图像生成领域的最新技术水平。该模型在提示词遵循、视觉质量、图像细节和输出多样性方面均达到顶尖水平。根据官方介绍，其性能超越了 Midjourney v6.0、DALL·E 3 (HD) 和 SD3-Ultra 等主流模型。该模型支持 0.1 到 2.0 兆像素范围内的多种纵横比和分辨率",
        "tags": [
            "12B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/blackforestlabs.svg",
        "publishTime": {
            "seconds": 1722441600
        },
        "size": 12,
        "contextLen": 0,
        "price": "0.37",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "FLUX.1 [pro]",
        "sort": 2800,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ Image",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": true,
        "supportFT": false,
        "targetModelName": "black-forest-labs/FLUX.1-pro"
    },
    {
        "modelId": "17885302590",
        "modelName": "Qwen/Qwen2-VL-72B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等",
        "tags": [
            "72B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726502400
        },
        "size": 72,
        "contextLen": 32768,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-VL-72B-Instruct",
        "sort": 2790,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": true,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-VL-72B-Instruct"
    },
    {
        "modelId": "17885302591",
        "modelName": "OpenGVLab/InternVL2-26B",
        "mf": "InternVL",
        "desc": "InternVL2-26B 是 InternVL 2.0 系列多模态大语言模型中的一员。该模型由 InternViT-6B-448px-V1-5 视觉模型、MLP 投影层和 internlm2-chat-20b 语言模型组成。它在各种视觉语言任务上展现出了卓越的性能，包括文档和图表理解、场景文本理解、OCR、科学和数学问题解决等。InternVL2-26B 使用 8K 上下文窗口训练，能够处理长文本、多图像和视频输入，显著提升了模型在这些任务上的处理能力",
        "tags": [
            "26B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/internlm.svg",
        "publishTime": {
            "seconds": 1720108800
        },
        "size": 26,
        "contextLen": 32768,
        "price": "1",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "InternVL2-26B",
        "sort": 2780,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": true,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "OpenGVLab/InternVL2-26B"
    },
    {
        "modelId": "17885302648",
        "modelName": "Lightricks/LTX-Video",
        "mf": "Lightricks",
        "desc": "LTX-Video 是首个基于 DiT 架构的实时视频生成模型，能够生成高质量视频，其生成速度甚至快于视频播放速度。该模型支持 24 帧每秒、768x512 分辨率的视频生成，既可以进行文本到视频的生成，也支持图像加文本到视频的转换。模型在大规模多样化视频数据集上进行训练，能够生成高分辨率、真实且内容丰富的视频",
        "tags": [
            "2B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Lightricks.png",
        "publishTime": {
            "seconds": 1732204800
        },
        "size": 2,
        "contextLen": 0,
        "price": "0.14",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "video",
        "subType": "text-to-video",
        "DisplayName": "LTX-Video",
        "sort": 2710,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 200
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 300
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 500
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 600
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 5,
                "IPD": 3000
            }
        ],
        "priceUnit": "/ Video",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Lightricks/LTX-Video"
    },
    {
        "modelId": "17885302587",
        "modelName": "Qwen/Qwen2.5-72B-Instruct-128K",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。它支持长达 128K tokens 的上下文。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "72B",
            "128K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 72,
        "contextLen": 131072,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-72B-Instruct-128K",
        "sort": 2610,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2.5-72B-Instruct-128K"
    },
    {
        "modelId": "17885302572",
        "modelName": "Qwen/Qwen2.5-72B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "72B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 72,
        "contextLen": 32768,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [
            "HOT"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-72B-Instruct",
        "sort": 2600,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": true,
        "targetModelName": "Qwen/Qwen2.5-72B-Instruct"
    },
    {
        "modelId": "17885302689",
        "modelName": "deepseek-ai/deepseek-vl2",
        "mf": "deepseek-ai",
        "desc": "DeepSeek-VL2 是一个基于 DeepSeekMoE-27B 开发的混合专家（MoE）视觉语言模型，采用稀疏激活的 MoE 架构，在仅激活 4.5B 参数的情况下实现了卓越性能。该模型在视觉问答、光学字符识别、文档/表格/图表理解和视觉定位等多个任务中表现优异，与现有的开源稠密模型和基于 MoE 的模型相比，在使用相同或更少的激活参数的情况下，实现了具有竞争力的或最先进的性能表现",
        "tags": [
            "MoE",
            "27B",
            "4K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DeepSeek.svg",
        "publishTime": {
            "seconds": 1734019200
        },
        "size": -1,
        "contextLen": 4096,
        "price": "0.99",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "deepseek-vl2",
        "sort": 2600,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": true,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/deepseek-vl2"
    },
    {
        "modelId": "17885302575",
        "modelName": "Qwen/Qwen2.5-32B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "32B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726675200
        },
        "size": 32,
        "contextLen": 32768,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [
            "HOT"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-32B-Instruct",
        "sort": 2590,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": true,
        "targetModelName": "Qwen/Qwen2.5-32B-Instruct"
    },
    {
        "modelId": "17885302574",
        "modelName": "Qwen/Qwen2.5-14B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-14B-Instruct 是阿里云发布的最新大语言模型系列之一。该 14B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "14B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 14,
        "contextLen": 32768,
        "price": "0.7",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-14B-Instruct",
        "sort": 2580,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": true,
        "targetModelName": "Qwen/Qwen2.5-14B-Instruct"
    },
    {
        "modelId": "17885302573",
        "modelName": "Qwen/Qwen2.5-7B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "Free",
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [
            "HOT"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-7B-Instruct (Free)",
        "sort": 2570,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": true,
        "targetModelName": "Qwen/Qwen2.5-7B-Instruct"
    },
    {
        "modelId": "17885302578",
        "modelName": "Qwen/Qwen2.5-Coder-7B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础",
        "tags": [
            "Coder",
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726761600
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-Coder-7B-Instruct (Free)",
        "sort": 2550,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": true,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2.5-Coder-7B-Instruct"
    },
    {
        "modelId": "17885302554",
        "modelName": "black-forest-labs/FLUX.1-dev",
        "mf": "black-forest-labs",
        "desc": "FLUX.1 [dev] 是一个 120 亿参数的 Rectified Flow Transformer 模型，能够根据文本描述生成图像。该模型具有最先进的输出质量，仅次于其最先进的模型 FLUX.1 [pro]。它具有竞争力的提示跟随能力，可匹配封闭源替代方案的性能。该模型使用引导蒸馏技术进行训练，提高了效率。开放权重以推动新的科学研究，并使艺术家能够开发创新的工作流程",
        "tags": [
            "12B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/blackforestlabs.svg",
        "publishTime": {
            "seconds": 1722441600
        },
        "size": 12,
        "contextLen": 0,
        "price": "0.0032",
        "currency": "¥",
        "operationLabel": [
            "HOT"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "FLUX.1-dev",
        "sort": 2500,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": true,
        "targetModelName": "black-forest-labs/FLUX.1-dev"
    },
    {
        "modelId": "17885302553",
        "modelName": "black-forest-labs/FLUX.1-schnell",
        "mf": "black-forest-labs",
        "desc": "FLUX.1 [schnell] 是一个 120 亿参数的 Rectified Flow Transformer 模型，能够根据文本描述生成图像。该模型采用潜在对抗扩散蒸馏技术训练，可以在1到4步内生成高质量图像。它具有最先进的输出质量和具有竞争力的提示跟随能力，匹配封闭源替代方案的性能。该模型在 Apache 2.0 许可下发布，可用于个人、科学和商业目的",
        "tags": [
            "Free",
            "12B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/blackforestlabs.svg",
        "publishTime": {
            "seconds": 1722441600
        },
        "size": 12,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "FLUX.1-schnell",
        "sort": 2200,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "black-forest-labs/FLUX.1-schnell"
    },
    {
        "modelId": "17885302584",
        "modelName": "TeleAI/TeleChat2",
        "mf": "DianXin",
        "desc": "TeleChat2大模型是由中国电信从0到1自主研发的生成式语义大模型，支持百科问答、代码生成、长文生成等功能，为用户提供对话咨询服务，能够与用户进行对话互动，回答问题，协助创作，高效便捷地帮助用户获取信息、知识和灵感。模型在幻觉问题、长文生成、逻辑理解等方面均有较出色表现。",
        "tags": [
            "8K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Property%201%3D5G.svg",
        "publishTime": {
            "seconds": 1727280000
        },
        "size": 110,
        "contextLen": 8192,
        "price": "1.33",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "TeleChat2",
        "sort": 2199,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "TeleAI/TeleChat2"
    },
    {
        "modelId": "17885302561",
        "modelName": "internlm/internlm2_5-20b-chat",
        "mf": "internlm",
        "desc": "InternLM2.5-20B-Chat 是一个开源的大规模对话模型，基于 InternLM2 架构开发。该模型拥有 200 亿参数，在数学推理方面表现出色，超越了同量级的 Llama3 和 Gemma2-27B 模型。InternLM2.5-20B-Chat 在工具调用能力方面有显著提升，支持从上百个网页收集信息进行分析推理，并具备更强的指令理解、工具选择和结果反思能力。它适用于构建复杂智能体，可进行多轮工具调用以完成复杂任务",
        "tags": [
            "20B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/internlm.svg",
        "publishTime": {
            "seconds": 1722268800
        },
        "size": 20,
        "contextLen": 32768,
        "price": "1",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "InternLM2.5-20B-Chat",
        "sort": 2180,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "internlm/internlm2_5-20b-chat"
    },
    {
        "modelId": "17885302535",
        "modelName": "internlm/internlm2_5-7b-chat",
        "mf": "internlm",
        "desc": "InternLM2.5-7B-Chat 是一个开源的对话模型，基于 InternLM2 架构开发。该 7B 参数规模的模型专注于对话生成任务，支持中英双语交互。模型采用了最新的训练技术，旨在提供流畅、智能的对话体验。InternLM2.5-7B-Chat 适用于各种对话应用场景，包括但不限于智能客服、个人助手等领域",
        "tags": [
            "Free",
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/internlm.svg",
        "publishTime": {
            "seconds": 1719417600
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "InternLM2.5-7B-Chat (Free)",
        "sort": 2170,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "internlm/internlm2_5-7b-chat"
    },
    {
        "modelId": "17885302555",
        "modelName": "meta-llama/Meta-Llama-3.1-405B-Instruct",
        "mf": "meta-llama3.1",
        "desc": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 405B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "tags": [
            "405B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1721664000
        },
        "size": 405,
        "contextLen": 32768,
        "price": "21",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3.1-405B-Instruct",
        "sort": 2010,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 10000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 15000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 125000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "meta-llama/Meta-Llama-3.1-405B-Instruct"
    },
    {
        "modelId": "17885302549",
        "modelName": "meta-llama/Meta-Llama-3.1-8B-Instruct",
        "mf": "meta-llama3.1",
        "desc": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 8B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "tags": [
            "Free",
            "8B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1721664000
        },
        "size": 8,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3.1-8B-Instruct (Free)",
        "sort": 2001,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": true,
        "targetModelName": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    {
        "modelId": "17885302551",
        "modelName": "meta-llama/Meta-Llama-3.1-70B-Instruct",
        "mf": "meta-llama3.1",
        "desc": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 70B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "tags": [
            "70B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1721664000
        },
        "size": 70,
        "contextLen": 32768,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3.1-70B-Instruct",
        "sort": 2001,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "meta-llama/Meta-Llama-3.1-70B-Instruct"
    },
    {
        "modelId": "17885302558",
        "modelName": "netease-youdao/bce-embedding-base_v1",
        "mf": "netease-youdao",
        "desc": "bce-embedding-base_v1 是由网易有道开发的双语和跨语言嵌入模型。该模型在中英文语义表示和检索任务中表现出色，尤其擅长跨语言场景。它是为检索增强生成（RAG）系统优化的，可以直接应用于教育、医疗、法律等多个领域。该模型不需要特定指令即可使用，能够高效地生成语义向量，为语义搜索和问答系统提供关键支持",
        "tags": [
            "多语言",
            "768 维",
            "279M",
            "512"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/netease-youdao.svg",
        "publishTime": {
            "seconds": 1704211200
        },
        "size": 0,
        "contextLen": 512,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "embedding",
        "DisplayName": "bce-embedding-base_v1",
        "sort": 2001,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "netease-youdao/bce-embedding-base_v1"
    },
    {
        "modelId": "17885302559",
        "modelName": "BAAI/bge-m3",
        "mf": "BAAI",
        "desc": "BGE-M3 是一个多功能、多语言、多粒度的文本嵌入模型。它支持三种常见的检索功能：密集检索、多向量检索和稀疏检索。该模型可以处理超过100种语言，并且能够处理从短句到长达8192个词元的长文档等不同粒度的输入。BGE-M3在多语言和跨语言检索任务中表现出色，在 MIRACL 和 MKQA 等基准测试中取得了领先结果。它还具有处理长文档检索的能力，在 MLDR 和 NarritiveQA 等数据集上展现了优秀性能",
        "tags": [
            "多语言",
            "1024 维",
            "8K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/BAAI.svg",
        "publishTime": {
            "seconds": 1706371200
        },
        "size": 0,
        "contextLen": 8192,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "embedding",
        "DisplayName": "bge-m3",
        "sort": 2001,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "BAAI/bge-m3"
    },
    {
        "modelId": "17885302563",
        "modelName": "netease-youdao/bce-reranker-base_v1",
        "mf": "netease-youdao",
        "desc": "bce-reranker-base_v1 是网易有道开发的双语和跨语言重排序模型，支持中文、英文、日文和韩文。该模型在 RAG 系统中用于精确重排检索结果，可以提供有意义的相关性分数，有助于过滤低质量段落。它针对多种 RAG 任务进行了优化，包括翻译、摘要和问答等。该模型无需特定指令即可使用，具有广泛的领域适应性，已在有道的多个产品中得到验证",
        "tags": [
            "多语言",
            "279M",
            "512"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/netease-youdao.svg",
        "publishTime": {
            "seconds": 1704211200
        },
        "size": 0,
        "contextLen": 512,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "reranker",
        "DisplayName": "bce-reranker-base_v1",
        "sort": 2001,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "netease-youdao/bce-reranker-base_v1"
    },
    {
        "modelId": "17885302564",
        "modelName": "BAAI/bge-reranker-v2-m3",
        "mf": "BAAI",
        "desc": "BAAI/bge-reranker-v2-m3 是一个轻量级的多语言重排序模型。它基于 bge-m3 模型开发，具有强大的多语言能力，易于部署，并且推理速度快。该模型采用查询和文档作为输入，直接输出相似度分数，而不是嵌入向量。它适用于多语言场景，特别是在中文和英文处理方面表现出色",
        "tags": [
            "多语言",
            "568M",
            "8K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/BAAI.svg",
        "publishTime": {
            "seconds": 1710432000
        },
        "size": 0,
        "contextLen": 8192,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "reranker",
        "DisplayName": "bge-reranker-v2-m3",
        "sort": 2001,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "BAAI/bge-reranker-v2-m3"
    },
    {
        "modelId": "17885302524",
        "modelName": "Qwen/Qwen2-7B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升",
        "tags": [
            "Free",
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1717430400
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-7B-Instruct (Free)",
        "sort": 1920,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-7B-Instruct"
    },
    {
        "modelId": "17885302529",
        "modelName": "Qwen/Qwen2-1.5B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少",
        "tags": [
            "Free",
            "1.5B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1717344000
        },
        "size": 2,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-1.5B-Instruct (Free)",
        "sort": 1919,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-1.5B-Instruct"
    },
    {
        "modelId": "17885302522",
        "modelName": "THUDM/glm-4-9b-chat",
        "mf": "THUDM",
        "desc": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用",
        "tags": [
            "Free",
            "9B",
            "128K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Zhipu.svg",
        "publishTime": {
            "seconds": 1717430400
        },
        "size": 9,
        "contextLen": 131072,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "glm-4-9b-chat (Free)",
        "sort": 1914,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "THUDM/glm-4-9b-chat"
    },
    {
        "modelId": "17885302519",
        "modelName": "THUDM/chatglm3-6b",
        "mf": "THUDM",
        "desc": "ChatGLM3-6B 是 ChatGLM 系列的开源模型，由智谱 AI 开发。该模型保留了前代模型的优秀特性，如对话流畅和部署门槛低，同时引入了新的特性。它采用了更多样的训练数据、更充分的训练步数和更合理的训练策略，在 10B 以下的预训练模型中表现出色。ChatGLM3-6B 支持多轮对话、工具调用、代码执行和 Agent 任务等复杂场景。除对话模型外，还开源了基础模型 ChatGLM-6B-Base 和长文本对话模型 ChatGLM3-6B-32K。该模型对学术研究完全开放，在登记后也允许免费商业使用",
        "tags": [
            "Free",
            "6B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Zhipu.svg",
        "publishTime": {
            "seconds": 1698163200
        },
        "size": 6,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "chatglm3-6b (Free)",
        "sort": 1913,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "THUDM/chatglm3-6b"
    },
    {
        "modelId": "17885302517",
        "modelName": "01-ai/Yi-1.5-9B-Chat-16K",
        "mf": "01-ai",
        "desc": "Yi-1.5-9B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在同等规模的开源模型中表现最佳",
        "tags": [
            "Free",
            "9B",
            "16K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Yi.svg",
        "publishTime": {
            "seconds": 1715702400
        },
        "size": 9,
        "contextLen": 16384,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Yi-1.5-9B-Chat-16K (Free)",
        "sort": 1912,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "01-ai/Yi-1.5-9B-Chat-16K"
    },
    {
        "modelId": "17885302516",
        "modelName": "01-ai/Yi-1.5-6B-Chat",
        "mf": "01-ai",
        "desc": "Yi-1.5-6B-Chat 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型具有 4K、16K 和 32K 的上下文长度版本，预训练总量达到 3.6T 个 token",
        "tags": [
            "Free",
            "6B",
            "4K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Yi.svg",
        "publishTime": {
            "seconds": 1715356800
        },
        "size": 6,
        "contextLen": 4096,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Yi-1.5-6B-Chat (Free)",
        "sort": 1911,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "01-ai/Yi-1.5-6B-Chat"
    },
    {
        "modelId": "17885302518",
        "modelName": "01-ai/Yi-1.5-34B-Chat-16K",
        "mf": "01-ai",
        "desc": "Yi-1.5-34B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在大多数基准测试中与更大的模型相当或表现更佳，具有 16K 的上下文长度",
        "tags": [
            "34B",
            "16K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Yi.svg",
        "publishTime": {
            "seconds": 1715702400
        },
        "size": 34,
        "contextLen": 16384,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Yi-1.5-34B-Chat-16K",
        "sort": 1812,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "01-ai/Yi-1.5-34B-Chat-16K"
    },
    {
        "modelId": "17885302526",
        "modelName": "stabilityai/stable-diffusion-3-medium",
        "mf": "stabilityai",
        "desc": "Stable Diffusion 3 Medium 是由 Stability AI 开发的多模态扩散变换器（MMDiT）文本到图像模型。该模型在图像质量、排版、复杂提示理解和资源效率方面有显著提升。它使用了三个固定的预训练文本编码器（OpenCLIP-ViT/G、CLIP-ViT/L 和 T5-xxl）。该模型在 10 亿张图像上进行了预训练，并在 3000 万张高质量美学图像和 300 万张偏好数据图像上进行了微调。Stable Diffusion 3 Medium 适用于艺术创作、设计过程、教育工具和生成模型研究等领域",
        "tags": [
            "2B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Stability.svg",
        "publishTime": {
            "seconds": 1718121600
        },
        "size": 2,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "stable-diffusion-3-medium",
        "sort": 1810,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "stabilityai/stable-diffusion-3-medium"
    },
    {
        "modelId": "17885302533",
        "modelName": "google/gemma-2-9b-it",
        "mf": "google",
        "desc": "Gemma 是 Google 开发的轻量级、最先进的开放模型系列之一。它是一个仅解码器的大型语言模型，支持英语，提供开放权重、预训练变体和指令微调变体。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。该 9B 模型是通过 8 万亿个 tokens 训练而成。其相对较小的规模使其可以在资源有限的环境中部署，如笔记本电脑、台式机或您自己的云基础设施，从而使更多人能够访问最先进的 AI 模型并促进创新",
        "tags": [
            "Free",
            "9B",
            "8K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Google.svg",
        "publishTime": {
            "seconds": 1719158400
        },
        "size": 9,
        "contextLen": 8192,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "gemma-2-9b-it (Free)",
        "sort": 1801,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "google/gemma-2-9b-it"
    },
    {
        "modelId": "17885302534",
        "modelName": "google/gemma-2-27b-it",
        "mf": "google",
        "desc": "Gemma 是由 Google 开发的轻量级、最先进的开放模型系列，采用与 Gemini 模型相同的研究和技术构建。这些模型是仅解码器的大型语言模型，支持英语，提供预训练和指令微调两种变体的开放权重。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。其相对较小的规模使其能够部署在资源有限的环境中，如笔记本电脑、台式机或个人云基础设施，从而让所有人都能获得最先进的 AI 模型，促进创新",
        "tags": [
            "27B",
            "8K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Google.svg",
        "publishTime": {
            "seconds": 1719158400
        },
        "size": 27,
        "contextLen": 8192,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "gemma-2-27b-it",
        "sort": 1801,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "google/gemma-2-27b-it"
    },
    {
        "modelId": "17885302536",
        "modelName": "BAAI/bge-large-en-v1.5",
        "mf": "BAAI",
        "desc": "BAAI/bge-large-en-v1.5 是一个大型英文文本嵌入模型，是 BGE (BAAI General Embedding) 系列的一部分。它在 MTEB 基准测试中取得了优异的表现，在 56 个数据集上的平均得分为 64.23，在检索、聚类、文本对分类等多个任务中表现出色。该模型支持最大 512 个 token 的输入长度，适用于各种自然语言处理任务，如文本检索、语义相似度计算等",
        "tags": [
            "英文",
            "1024 维",
            "335M",
            "512"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/BAAI.svg",
        "publishTime": {
            "seconds": 1694448000
        },
        "size": 0,
        "contextLen": 512,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "embedding",
        "DisplayName": "bge-large-en-v1.5",
        "sort": 1801,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "BAAI/bge-large-en-v1.5"
    },
    {
        "modelId": "17885302537",
        "modelName": "BAAI/bge-large-zh-v1.5",
        "mf": "BAAI",
        "desc": "BAAI/bge-large-zh-v1.5 是一个大型中文文本嵌入模型，是 BGE (BAAI General Embedding) 系列的一部分。该模型在 C-MTEB 基准测试中表现出色，在 31 个数据集上的平均得分为 64.53，在检索、语义相似度、文本对分类等多个任务中都取得了优异成绩。它支持最大 512 个 token 的输入长度，适用于各种中文自然语言处理任务，如文本检索、语义相似度计算等",
        "tags": [
            "中文",
            "1024 维",
            "335M",
            "512"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/BAAI.svg",
        "publishTime": {
            "seconds": 1694448000
        },
        "size": 0,
        "contextLen": 512,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "embedding",
        "DisplayName": "bge-large-zh-v1.5",
        "sort": 1801,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 2000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "BAAI/bge-large-zh-v1.5"
    },
    {
        "modelId": "17885302556",
        "modelName": "FunAudioLLM/SenseVoiceSmall",
        "mf": "FunAudioLLM",
        "desc": "SenseVoice 是一个具有多种语音理解能力的语音基础模型，包括自动语音识别（ASR）、口语语言识别（LID）、语音情感识别（SER）和音频事件检测（AED）。SenseVoice-Small 模型采用非自回归端到端框架，具有非常低的推理延迟。它支持 50 多种语言的多语言语音识别，在中文和粤语识别方面表现优于 Whisper 模型。此外，它还具有出色的情感识别和音频事件检测能力。该模型处理 10 秒音频仅需 70 毫秒，比 Whisper-Large 快 15 倍",
        "tags": [
            "多语言"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/FunAudioLLM.png",
        "publishTime": {
            "seconds": 1721664000
        },
        "size": 0,
        "contextLen": 0,
        "price": "0.0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "audio",
        "subType": "speech-to-text",
        "DisplayName": "SenseVoiceSmall",
        "sort": 1801,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "FunAudioLLM/SenseVoiceSmall"
    },
    {
        "modelId": "17885302492",
        "modelName": "stabilityai/stable-diffusion-xl-base-1.0",
        "mf": "stabilityai",
        "desc": "Stable Diffusion XL（SDXL）是一个基于潜在扩散的文本到图像生成模型，使用了两个固定的预训练文本编码器（OpenCLIP-ViT/G 和 CLIP-ViT/L）。SDXL 由基础模型和精炼模型组成，可以单独使用基础模型或结合两者以获得更好的效果。该模型在生成艺术作品、设计和创意工具应用等方面表现出色，但仅限于研究目的使用",
        "tags": [
            "图生图"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Stability.svg",
        "publishTime": {
            "seconds": 1690214400
        },
        "size": 0,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "image-to-image",
        "DisplayName": "stable-diffusion-xl-base-1.0",
        "sort": 1801,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "stabilityai/stable-diffusion-xl-base-1.0"
    },
    {
        "modelId": "17885302500",
        "modelName": "stabilityai/stable-diffusion-2-1",
        "mf": "stabilityai",
        "desc": "Stable Diffusion v2-1 是一个基于潜在扩散的文本到图像生成模型。该模型使用固定的预训练 OpenCLIP-ViT/H 文本编码器，可用于生成和修改基于文本提示的图像。它是从 Stable Diffusion v2 模型微调而来，在相同数据集上额外训练了 55,000 步，然后再训练了 155,000 步。该模型主要用于研究目的，包括艺术创作、设计应用和创意工具等领域",
        "tags": [
            "图生图"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Stability.svg",
        "publishTime": {
            "seconds": 1670342400
        },
        "size": 0,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "stable-diffusion-2-1",
        "sort": 1801,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "stabilityai/stable-diffusion-2-1"
    },
    {
        "modelId": "17885302657",
        "modelName": "AIDC-AI/Marco-o1",
        "mf": "AIDC-AI",
        "desc": "Marco-o1 是一个开放推理模型，由阿里巴巴国际数字商务 MarcoPolo 团队开发。该模型不仅专注于数学、物理和编程等标准答案领域，更重视开放性解决方案。它采用了思维链（CoT）微调、蒙特卡洛树搜索（MCTS）以及反思机制等创新推理策略，以提升复杂现实问题的解决能力。在 MGSM 数据集上，该模型在英文和中文测试中分别实现了 +6.17% 和 +5.60% 的准确率提升",
        "tags": [
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/AIDC_AI.png",
        "publishTime": {
            "seconds": 1732032000
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [
            "New"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Marco-o1",
        "sort": 1000,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "AIDC-AI/Marco-o1"
    },
    {
        "modelId": "17885302683",
        "modelName": "LoRA/meta-llama/Meta-Llama-3.1-8B-Instruct",
        "mf": "meta-llama3.1 (LoRA)",
        "desc": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 8B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "tags": [
            "Free",
            "8B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1721664000
        },
        "size": 8,
        "contextLen": 32768,
        "price": "0.63",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3.1-8B-Instruct (LoRA)",
        "sort": 601,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "LoRA/meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    {
        "modelId": "17885302660",
        "modelName": "LoRA/Qwen/Qwen2.5-32B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "32B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726675200
        },
        "size": 32,
        "contextLen": 32768,
        "price": "1.89",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-32B-Instruct (LoRA)",
        "sort": 590,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "LoRA/Qwen/Qwen2.5-32B-Instruct"
    },
    {
        "modelId": "17885302659",
        "modelName": "LoRA/Qwen/Qwen2.5-14B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-14B-Instruct 是阿里云发布的最新大语言模型系列之一。该 14B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "14B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 14,
        "contextLen": 32768,
        "price": "1.05",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-14B-Instruct (LoRA)",
        "sort": 580,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "LoRA/Qwen/Qwen2.5-14B-Instruct"
    },
    {
        "modelId": "17885302595",
        "modelName": "Vendor-A/Qwen/Qwen2.5-72B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "72B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 72,
        "contextLen": 32768,
        "price": "1",
        "currency": "¥",
        "operationLabel": [
            "国芯"
        ],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-72B-Instruct (Vendor-A)",
        "sort": 302,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Vendor-A/Qwen/Qwen2.5-72B-Instruct"
    },
    {
        "modelId": "17885302610",
        "modelName": "Pro/Qwen/Qwen2.5-Coder-7B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-Coder-7B-Instruct 是阿里云发布的代码特定大语言模型系列的最新版本。该模型在 Qwen2.5 的基础上，通过 5.5 万亿个 tokens 的训练，显著提升了代码生成、推理和修复能力。它不仅增强了编码能力，还保持了数学和通用能力的优势。模型为代码智能体等实际应用提供了更全面的基础",
        "tags": [
            "Coder",
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726761600
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-Coder-7B-Instruct (Pro)",
        "sort": 230,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": true,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2.5-Coder-7B-Instruct"
    },
    {
        "modelId": "17885302596",
        "modelName": "Pro/Qwen/Qwen2-VL-7B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-VL-7B-Instruct 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够用于高质量的基于视频的问答、对话和内容创作，还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。除了英语和中文，Qwen2-VL 现在还支持理解图像中不同语言的文本，包括大多数欧洲语言、日语、韩语、阿拉伯语和越南语等",
        "tags": [
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1724860800
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-VL-7B-Instruct (Pro)",
        "sort": 220,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": true,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-VL-7B-Instruct"
    },
    {
        "modelId": "17885302594",
        "modelName": "Pro/OpenGVLab/InternVL2-8B",
        "mf": "InternVL",
        "desc": "InternVL2-8B 是 InternVL 2.0 系列多模态大语言模型中的一员。该模型由 InternViT-300M-448px 视觉模型、MLP 投影层和 internlm2_5-7b-chat 语言模型组成。它在各种视觉语言任务上展现出了卓越的性能，包括文档和图表理解、场景文本理解、OCR、科学和数学问题解决等。InternVL2-8B 使用 8K 上下文窗口训练，能够处理长文本、多图像和视频输入，显著提升了模型在这些任务上的处理能力",
        "tags": [
            "8B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/internlm.svg",
        "publishTime": {
            "seconds": 1720108800
        },
        "size": 8,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "InternVL2-8B (Pro)",
        "sort": 218,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": true,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "OpenGVLab/InternVL2-8B"
    },
    {
        "modelId": "17885302576",
        "modelName": "Pro/black-forest-labs/FLUX.1-schnell",
        "mf": "black-forest-labs",
        "desc": "FLUX.1 [schnell] 是一个 120 亿参数的 Rectified Flow Transformer 模型，能够根据文本描述生成图像。该模型采用潜在对抗扩散蒸馏技术训练，可以在1到4步内生成高质量图像。它具有最先进的输出质量和具有竞争力的提示跟随能力，匹配封闭源替代方案的性能。该模型在 Apache 2.0 许可下发布，可用于个人、科学和商业目的",
        "tags": [
            "12B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/blackforestlabs.svg",
        "publishTime": {
            "seconds": 1722441600
        },
        "size": 12,
        "contextLen": 0,
        "price": "0.0024",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "FLUX.1-schnell (Pro)",
        "sort": 209,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "black-forest-labs/FLUX.1-schnell"
    },
    {
        "modelId": "17885302592",
        "modelName": "Pro/BAAI/bge-m3",
        "mf": "BAAI",
        "desc": "BGE-M3 是一个多功能、多语言、多粒度的文本嵌入模型。它支持三种常见的检索功能：密集检索、多向量检索和稀疏检索。该模型可以处理超过100种语言，并且能够处理从短句到长达8192个词元的长文档等不同粒度的输入。BGE-M3在多语言和跨语言检索任务中表现出色，在 MIRACL 和 MKQA 等基准测试中取得了领先结果。它还具有处理长文档检索的能力，在 MLDR 和 NarritiveQA 等数据集上展现了优秀性能",
        "tags": [
            "多语言",
            "1024 维",
            "8K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/BAAI.svg",
        "publishTime": {
            "seconds": 1706371200
        },
        "size": 0,
        "contextLen": 8192,
        "price": "0.07",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "embedding",
        "DisplayName": "bge-m3 (Pro)",
        "sort": 208,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 1000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 1,
                "RPM": 3000,
                "TPM": 1000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 2,
                "RPM": 5000,
                "TPM": 1000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 3,
                "RPM": 5000,
                "TPM": 5000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 4,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 10000000,
                "IPM": 1,
                "IPD": 1440
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "BAAI/bge-m3"
    },
    {
        "modelId": "17885302586",
        "modelName": "Pro/Qwen/Qwen2.5-7B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-7B-Instruct (Pro)",
        "sort": 207,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": true,
        "targetModelName": "Qwen/Qwen2.5-7B-Instruct"
    },
    {
        "modelId": "17885302644",
        "modelName": "Pro/BAAI/bge-reranker-v2-m3",
        "mf": "BAAI",
        "desc": "BAAI/bge-reranker-v2-m3 是一个轻量级的多语言重排序模型。它基于 bge-m3 模型开发，具有强大的多语言能力，易于部署，并且推理速度快。该模型采用查询和文档作为输入，直接输出相似度分数，而不是嵌入向量。它适用于多语言场景，特别是在中文和英文处理方面表现出色",
        "tags": [
            "多语言",
            "568M",
            "8K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/BAAI.svg",
        "publishTime": {
            "seconds": 1710432000
        },
        "size": 0,
        "contextLen": 8192,
        "price": "0.07",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "reranker",
        "DisplayName": "bge-reranker-v2-m3 (Pro)",
        "sort": 207,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 2000,
                "TPM": 1000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 1,
                "RPM": 3000,
                "TPM": 1000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 2,
                "RPM": 5000,
                "TPM": 1000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 3,
                "RPM": 5000,
                "TPM": 5000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 4,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": 1,
                "IPD": 1440
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 10000000,
                "IPM": 1,
                "IPD": 1440
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "BAAI/bge-reranker-v2-m3"
    },
    {
        "modelId": "17885302550",
        "modelName": "Pro/meta-llama/Meta-Llama-3.1-8B-Instruct",
        "mf": "meta-llama3.1",
        "desc": "Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 8B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3.1 支持文本生成和代码生成，知识截止日期为 2023 年 12 月",
        "tags": [
            "8B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1721664000
        },
        "size": 8,
        "contextLen": 32768,
        "price": "0.42",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3.1-8B-Instruct (Pro)",
        "sort": 190,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "meta-llama/Meta-Llama-3.1-8B-Instruct"
    },
    {
        "modelId": "17885302707",
        "modelName": "LoRA/black-forest-labs/FLUX.1-dev",
        "mf": "black-forest-labs",
        "desc": "FLUX.1 [dev] 是一个 120 亿参数的 Rectified Flow Transformer 模型，能够根据文本描述生成图像。该模型具有最先进的输出质量，仅次于其最先进的模型 FLUX.1 [pro]。它具有竞争力的提示跟随能力，可匹配封闭源替代方案的性能。该模型使用引导蒸馏技术进行训练，提高了效率。开放权重以推动新的科学研究，并使艺术家能够开发创新的工作流程",
        "tags": [
            "12B"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/blackforestlabs.svg",
        "publishTime": {
            "seconds": 1722441600
        },
        "size": 12,
        "contextLen": 0,
        "price": "0.0048",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "FLUX.1-dev (LoRA)",
        "sort": 158,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "LoRA/black-forest-labs/FLUX.1-dev"
    },
    {
        "modelId": "17885302646",
        "modelName": "LoRA/RVC-Boss/GPT-SoVITS",
        "mf": "RVC-Boss",
        "desc": "GPT-SoVITS 是一个强大的少样本语音转换和文本转语音系统。其最显著的特点是仅需 1 分钟的训练数据即可实现高质量的声音克隆。模型支持零样本 TTS（仅需 5 秒语音样本）和少样本 TTS（使用 1 分钟训练数据进行微调）两种模式。该模型具有跨语言能力，支持英文、日文、韩文、粤语和中文等多种语言的推理，并集成了语音伴奏分离、自动训练集分割、中文 ASR 等实用工具",
        "tags": [],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/RVC.png",
        "publishTime": {
            "seconds": 1722960000
        },
        "size": 0,
        "contextLen": 0,
        "price": "50",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "audio",
        "subType": "text-to-speech",
        "DisplayName": "GPT-SoVITS (LoRA)",
        "sort": 138,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M UTF-8 bytes",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "LoRA/RVC-Boss/GPT-SoVITS"
    },
    {
        "modelId": "17885302614",
        "modelName": "LoRA/Qwen/Qwen2.5-72B-Instruct",
        "mf": "Qwen",
        "desc": "Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "72B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1730390400
        },
        "size": 0,
        "contextLen": 0,
        "price": "6.2",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-72B-Instrcut (LoRA)",
        "sort": 128,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "LoRA/Qwen/Qwen2.5-72B-Instruct"
    },
    {
        "modelId": "17885302538",
        "modelName": "Pro/Qwen/Qwen2-7B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力。Qwen2-7B-Instruct 在多项评测中均优于 Qwen1.5-7B-Chat，显示出显著的性能提升",
        "tags": [
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1717430400
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-7B-Instruct (Pro)",
        "sort": 120,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-7B-Instruct"
    },
    {
        "modelId": "17885302539",
        "modelName": "Pro/Qwen/Qwen2-1.5B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。与 Qwen1.5-1.8B-Chat 相比，Qwen2-1.5B-Instruct 在 MMLU、HumanEval、GSM8K、C-Eval 和 IFEval 等测试中均显示出显著的性能提升，尽管参数量略少",
        "tags": [
            "1.5B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1717344000
        },
        "size": 2,
        "contextLen": 32768,
        "price": "0.14",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-1.5B-Instruct (Pro)",
        "sort": 119,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-1.5B-Instruct"
    },
    {
        "modelId": "17885302603",
        "modelName": "LoRA/Qwen/Qwen2.5-7B-Instruct",
        "mf": "Qwen",
        "desc": "Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升",
        "tags": [
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726588800
        },
        "size": 0,
        "contextLen": 0,
        "price": "0.53",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-7B-Instrcut (LoRA)",
        "sort": 118,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "LoRA/Qwen/Qwen2.5-7B-Instruct"
    },
    {
        "modelId": "17885302541",
        "modelName": "Pro/THUDM/glm-4-9b-chat",
        "mf": "THUDM",
        "desc": "GLM-4-9B-Chat 是智谱 AI 推出的 GLM-4 系列预训练模型中的开源版本。该模型在语义、数学、推理、代码和知识等多个方面表现出色。除了支持多轮对话外，GLM-4-9B-Chat 还具备网页浏览、代码执行、自定义工具调用（Function Call）和长文本推理等高级功能。模型支持 26 种语言，包括中文、英文、日语、韩语和德语等。在多项基准测试中，GLM-4-9B-Chat 展现了优秀的性能，如 AlignBench-v2、MT-Bench、MMLU 和 C-Eval 等。该模型支持最大 128K 的上下文长度，适用于学术研究和商业应用",
        "tags": [
            "9B",
            "128K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Zhipu.svg",
        "publishTime": {
            "seconds": 1717430400
        },
        "size": 9,
        "contextLen": 131072,
        "price": "0.6",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "glm-4-9b-chat (Pro)",
        "sort": 114,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "THUDM/glm-4-9b-chat"
    },
    {
        "modelId": "17885302545",
        "modelName": "Pro/google/gemma-2-9b-it",
        "mf": "google",
        "desc": "Gemma 是 Google 开发的轻量级、最先进的开放模型系列之一。它是一个仅解码器的大型语言模型，支持英语，提供开放权重、预训练变体和指令微调变体。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。该 9B 模型是通过 8 万亿个 tokens 训练而成。其相对较小的规模使其可以在资源有限的环境中部署，如笔记本电脑、台式机或您自己的云基础设施，从而使更多人能够访问最先进的 AI 模型并促进创新",
        "tags": [
            "9B",
            "8K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Google.svg",
        "publishTime": {
            "seconds": 1719158400
        },
        "size": 9,
        "contextLen": 0,
        "price": "0.6",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": true,
        "type": "text",
        "subType": "chat",
        "DisplayName": "gemma-2-9b-it(Pro)",
        "sort": 10,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "normal",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "google/gemma-2-9b-it"
    },
    {
        "modelId": "17885302528",
        "modelName": "deepseek-ai/DeepSeek-Coder-V2-Instruct",
        "mf": "deepseek-ai",
        "desc": "DeepSeek-Coder-V2 是一个开源的混合专家（MoE）代码语言模型，在代码相关任务中达到了与 GPT4-Turbo 相当的性能。它是在 DeepSeek-V2 的中间检查点基础上，通过额外 6 万亿个 token 的预训练而来。该模型显著提升了编码和数学推理能力，同时保持了通用语言任务的性能。相比 DeepSeek-Coder-33B，它在各方面都有显著进步，支持的编程语言从 86 种扩展到 338 种，上下文长度从 16K 扩展到 128K。在标准基准评估中，DeepSeek-Coder-V2 在编码和数学基准测试中的表现超过了 GPT4-Turbo、Claude 3 Opus 和 Gemini 1.5 Pro 等闭源模型",
        "tags": [
            "Coder",
            "MoE",
            "236B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DeepSeek.svg",
        "publishTime": {
            "seconds": 1718294400
        },
        "size": -1,
        "contextLen": 32768,
        "price": "1.33",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "DeepSeek-Coder-V2-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 10000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 15000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 125000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": true,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/DeepSeek-Coder-V2-Instruct"
    },
    {
        "modelId": "17885302540",
        "modelName": "Pro/Qwen/Qwen1.5-7B-Chat",
        "mf": "Qwen",
        "desc": "Qwen1.5-7B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置等技术，并改进了适用于多种自然语言和代码的分词器。该 7B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能",
        "tags": [
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1706630400
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Qwen1.5-7B-Chat (Pro)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen1.5-7B-Chat"
    },
    {
        "modelId": "17885302542",
        "modelName": "Pro/THUDM/chatglm3-6b",
        "mf": "THUDM",
        "desc": "ChatGLM3-6B 是 ChatGLM 系列的开源模型，由智谱 AI 开发。该模型保留了前代模型的优秀特性，如对话流畅和部署门槛低，同时引入了新的特性。它采用了更多样的训练数据、更充分的训练步数和更合理的训练策略，在 10B 以下的预训练模型中表现出色。ChatGLM3-6B 支持多轮对话、工具调用、代码执行和 Agent 任务等复杂场景。除对话模型外，还开源了基础模型 ChatGLM-6B-Base 和长文本对话模型 ChatGLM3-6B-32K。该模型对学术研究完全开放，在登记后也允许免费商业使用",
        "tags": [
            "6B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Zhipu.svg",
        "publishTime": {
            "seconds": 1698163200
        },
        "size": 6,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "chatglm3-6b (Pro)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "THUDM/chatglm3-6b"
    },
    {
        "modelId": "17885302543",
        "modelName": "Pro/01-ai/Yi-1.5-9B-Chat-16K",
        "mf": "01-ai",
        "desc": "Yi-1.5-9B-Chat-16K 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型在同等规模的开源模型中表现最佳",
        "tags": [
            "9B",
            "16K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Yi.svg",
        "publishTime": {
            "seconds": 1715702400
        },
        "size": 9,
        "contextLen": 16384,
        "price": "0.42",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Yi-1.5-9B-Chat-16K (Pro)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "01-ai/Yi-1.5-9B-Chat-16K"
    },
    {
        "modelId": "17885302544",
        "modelName": "Pro/01-ai/Yi-1.5-6B-Chat",
        "mf": "01-ai",
        "desc": "Yi-1.5-6B-Chat 是 Yi-1.5 系列的一个变体，属于开源聊天模型。Yi-1.5 是 Yi 的升级版本，在 500B 个高质量语料上进行了持续预训练，并在 3M 多样化的微调样本上进行了微调。相比于 Yi，Yi-1.5 在编码、数学、推理和指令遵循能力方面表现更强，同时保持了出色的语言理解、常识推理和阅读理解能力。该模型具有 4K、16K 和 32K 的上下文长度版本，预训练总量达到 3.6T 个 token",
        "tags": [
            "6B",
            "4K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Yi.svg",
        "publishTime": {
            "seconds": 1715356800
        },
        "size": 6,
        "contextLen": 4096,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Yi-1.5-6B-Chat (Pro)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "01-ai/Yi-1.5-6B-Chat"
    },
    {
        "modelId": "17885302546",
        "modelName": "Pro/internlm/internlm2_5-7b-chat",
        "mf": "internlm",
        "desc": "InternLM2.5-7B-Chat 是一个开源的对话模型，基于 InternLM2 架构开发。该 7B 参数规模的模型专注于对话生成任务，支持中英双语交互。模型采用了最新的训练技术，旨在提供流畅、智能的对话体验。InternLM2.5-7B-Chat 适用于各种对话应用场景，包括但不限于智能客服、个人助手等领域",
        "tags": [
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/internlm.svg",
        "publishTime": {
            "seconds": 1719417600
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "InternLM2.5-7B-Chat(Pro)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": true,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "internlm/internlm2_5-7b-chat"
    },
    {
        "modelId": "17885302547",
        "modelName": "Pro/meta-llama/Meta-Llama-3-8B-Instruct",
        "mf": "meta-llama3",
        "desc": "Meta Llama 3 是由 Meta 开发的大型语言模型家族，包括 8B 和 70B 两种参数规模的预训练和指令微调变体。该 8B 指令微调模型针对对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3 支持文本生成和代码生成，知识截止日期为 2023 年 3 月",
        "tags": [
            "8B",
            "8K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1713369600
        },
        "size": 8,
        "contextLen": 8192,
        "price": "0.42",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3-8B-Instruct(Pro)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "meta-llama/Meta-Llama-3-8B-Instruct"
    },
    {
        "modelId": "17885302548",
        "modelName": "Pro/mistralai/Mistral-7B-Instruct-v0.2",
        "mf": "mistralai",
        "desc": "Mistral-7B-Instruct-v0.2 是 Mistral-7B-v0.2 的指令微调版本。该模型在原基础模型上进行了改进，将上下文窗口扩展到 32k（v0.1 为 8k），使用了 Rope-theta = 1e6 的设置，并移除了滑动窗口注意力机制。这个指令微调模型针对对话场景进行了优化，可用于文本生成和对话任务。模型采用了监督微调等技术来提升性能，但目前尚未实现内容审核机制",
        "tags": [
            "7B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Mistral.svg",
        "publishTime": {
            "seconds": 1702224000
        },
        "size": 7,
        "contextLen": 0,
        "price": "0.35",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Mistral-7B-Instruct-v0.2(Pro)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 120000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 320000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 5000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "mistralai/Mistral-7B-Instruct-v0.2"
    },
    {
        "modelId": "17885302562",
        "modelName": "Qwen/Qwen2-Math-72B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-Math-72B-Instruct 是 Qwen2 数学系列中的指令微调大语言模型，参数规模为 72B。该模型专门针对数学和算术问题解决能力进行了优化，在数学推理方面表现出色，超越了开源模型甚至一些闭源模型（如 GPT4）的数学能力。它基于 Qwen2 系列构建，旨在解决需要复杂、多步逻辑推理的高级数学问题。该模型目前主要支持英语，双语（英语和中文）版本将很快发布",
        "tags": [
            "Math",
            "72B",
            "4K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1723132800
        },
        "size": 72,
        "contextLen": 4096,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Qwen2-Math-72B-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-Math-72B-Instruct"
    },
    {
        "modelId": "17885302571",
        "modelName": "Vendor-A/Qwen/Qwen2-72B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-72B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 72B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力",
        "tags": [
            "72B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1716825600
        },
        "size": 72,
        "contextLen": 32768,
        "price": "1",
        "currency": "¥",
        "operationLabel": [
            "国芯"
        ],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-72B-Instruct (Vendor-A)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Vendor-A/Qwen/Qwen2-72B-Instruct"
    },
    {
        "modelId": "17885302577",
        "modelName": "Qwen/Qwen2.5-Math-72B-Instruct",
        "mf": "Qwen2.5",
        "desc": "Qwen2.5-Math-72B 是阿里云发布的 Qwen2.5-Math 系列数学大语言模型之一。该模型支持使用思维链（CoT）和工具集成推理（TIR）方法解决中文和英文数学问题。相比前代 Qwen2-Math 系列，Qwen2.5-Math 系列在中英文数学基准测试中取得了显著的性能提升。该模型在处理精确计算、符号操作和算法操作方面表现出色，尤其适合解决复杂的数学和算法推理任务",
        "tags": [
            "Math",
            "72B",
            "4K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1726761600
        },
        "size": 72,
        "contextLen": 4096,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2.5-Math-72B-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2.5-Math-72B-Instruct"
    },
    {
        "modelId": "17885302593",
        "modelName": "OpenGVLab/InternVL2-Llama3-76B",
        "mf": "InternVL",
        "desc": "InternVL2-Llama3-76B 是 InternVL 2.0 系列中的大规模多模态模型。它由 InternViT-6B-448px-V1-5 视觉模型、MLP 投影层和 Hermes-2-Theta-Llama-3-70B 语言模型组成。该模型在各种视觉语言任务上表现出色，包括文档和图表理解、信息图表问答、场景文本理解和 OCR 任务等。InternVL2-Llama3-76B 使用 8K 上下文窗口训练，能够处理长文本、多图像和视频输入，显著提升了模型在这些任务上的处理能力，在多项基准测试中达到或接近最先进的商业模型水平",
        "tags": [
            "76B",
            "8K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/internlm.svg",
        "publishTime": {
            "seconds": 1720972800
        },
        "size": 76,
        "contextLen": 8192,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "InternVL2-Llama3-76B",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": true,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "OpenGVLab/InternVL2-Llama3-76B"
    },
    {
        "modelId": "17885302599",
        "modelName": "nvidia/Llama-3.1-Nemotron-70B-Instruct",
        "mf": "NVIDIA",
        "desc": "Llama-3.1-Nemotron-70B-Instruct 是由 NVIDIA 定制的大型语言模型，旨在提高 LLM 生成的响应对用户查询的帮助程度。该模型在 Arena Hard、AlpacaEval 2 LC 和 GPT-4-Turbo MT-Bench 等基准测试中表现出色，截至 2024 年 10 月 1 日，在所有三个自动对齐基准测试中排名第一。该模型使用 RLHF（特别是 REINFORCE）、Llama-3.1-Nemotron-70B-Reward 和 HelpSteer2-Preference 提示在 Llama-3.1-70B-Instruct 模型基础上进行训练",
        "tags": [
            "70B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/NVIDIA.svg",
        "publishTime": {
            "seconds": 1728662400
        },
        "size": 70,
        "contextLen": 32768,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Llama-3.1-Nemotron-70B-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "nvidia/Llama-3.1-Nemotron-70B-Instruct"
    },
    {
        "modelId": "17885302619",
        "modelName": "Tencent/Hunyuan-A52B-Instruct",
        "mf": "hunyuan",
        "desc": "混元大模型（Hunyuan-Large）是业界最大的开源 Transformer 架构 MoE 模型，拥有 3890 亿总参数量和 520 亿激活参数量。该模型采用了高质量合成数据训练、KV 缓存压缩、专家特定学习率缩放等创新技术。在 MMLU、CMMLU、数学推理等多个基准测试中都展现出优异表现",
        "tags": [
            "MoE",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/hunyuan.svg",
        "publishTime": {
            "seconds": 1730908800
        },
        "size": -1,
        "contextLen": 32768,
        "price": "21",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Hunyuan-A52B-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 10000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 15000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 125000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Tencent/Hunyuan-A52B-Instruct"
    },
    {
        "modelId": "17885302493",
        "modelName": "TencentARC/PhotoMaker",
        "mf": "TencentARC",
        "desc": "PhotoMaker 是一个由腾讯 ARC 实验室开发的文本到图像生成模型。该模型允许用户输入一张或几张人脸照片，并配合文本提示，在几秒钟内生成定制的照片或绘画（无需训练）。PhotoMaker 主要包含两个部分：经过微调的 OpenCLIP-ViT-H-14 编码器和一些融合层，以及应用于 UNet 所有注意力层的 LoRA 权重。该模型可以适配任何基于 SDXL 的基础模型，或与其他 LoRA 模块结合使用。PhotoMaker 在生成真实照片和风格化图像方面都表现出色，但在亚洲男性面孔和人手渲染方面仍有一些局限性",
        "tags": [
            "图生图"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/TencentARC.svg",
        "publishTime": {
            "seconds": 1705075200
        },
        "size": 0,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "image",
        "subType": "image-to-image",
        "DisplayName": "【Deprecated】PhotoMaker",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "TencentARC/PhotoMaker"
    },
    {
        "modelId": "17885302494",
        "modelName": "InstantX/InstantID",
        "mf": "InstantX",
        "desc": "InstantID 是一种新的最先进的免调整方法，只需一张图像就能实现保留 ID 的生成，支持各种下游任务。该方法引入了一个简单的即插即用模块，能够仅使用一张人脸图像就生成任何风格的个性化图像，同时保持高保真度。InstantID 包含三个关键组件：1) 捕获强语义人脸信息的 ID 嵌入；2) 具有解耦交叉注意力的轻量级适配模块，支持将图像作为视觉提示；3) 编码参考人脸图像详细特征的 IdentityNet。该方法无需微调即可实现高保真度的人脸保留，与现有的预训练扩散模型如 SD1.5 和 SDXL 无缝集成",
        "tags": [
            "图生图"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/InstantX.svg",
        "publishTime": {
            "seconds": 1705852800
        },
        "size": 0,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "image",
        "subType": "image-to-image",
        "DisplayName": "【Deprecated】InstantID",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "InstantX/InstantID"
    },
    {
        "modelId": "17885302496",
        "modelName": "mistralai/Mixtral-8x7B-Instruct-v0.1",
        "mf": "mistralai",
        "desc": "Mixtral-8x7B 是由 Mistral AI 开发的大型语言模型，采用稀疏混合专家（Sparse Mixture of Experts）架构。该指令微调模型针对对话场景进行了优化，在多项基准测试中表现优异，超越了 Llama 2 70B。模型支持多语言输入和输出，可用于文本生成和对话任务。Mixtral-8x7B 采用了监督微调等技术来提升模型性能，但目前尚未实现内容审核机制",
        "tags": [
            "MoE",
            "47B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Mistral.svg",
        "publishTime": {
            "seconds": 1702224000
        },
        "size": -1,
        "contextLen": 32768,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Mixtral-8x7B-Instruct-v0.1",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "mistralai/Mixtral-8x7B-Instruct-v0.1"
    },
    {
        "modelId": "17885302497",
        "modelName": "mistralai/Mistral-7B-Instruct-v0.2",
        "mf": "mistralai",
        "desc": "Mistral-7B-Instruct-v0.2 是 Mistral-7B-v0.2 的指令微调版本。该模型在原基础模型上进行了改进，将上下文窗口扩展到 32k（v0.1 为 8k），使用了 Rope-theta = 1e6 的设置，并移除了滑动窗口注意力机制。这个指令微调模型针对对话场景进行了优化，可用于文本生成和对话任务。模型采用了监督微调等技术来提升性能，但目前尚未实现内容审核机制",
        "tags": [
            "Free",
            "7B",
            "32K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Mistral.svg",
        "publishTime": {
            "seconds": 1702224000
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Mistral-7B-Instruct-v0.2 (Free)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "mistralai/Mistral-7B-Instruct-v0.2"
    },
    {
        "modelId": "17885302501",
        "modelName": "stabilityai/sd-turbo",
        "mf": "stabilityai",
        "desc": "SD-Turbo 是一个快速生成式文本到图像模型，由 Stability AI 开发。它是 Stable Diffusion 2.1 的蒸馏版本，使用了名为对抗性扩散蒸馏（ADD）的新训练方法。该模型能够在单次网络评估中，基于文本提示合成照片级真实的图像。SD-Turbo 主要用于研究小型、蒸馏的文本到图像模型，可以在 1 到 4 步内以高图像质量进行采样。该模型适用于实时应用研究、生成艺术作品以及在教育或创意工具中的应用",
        "tags": [],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Stability.svg",
        "publishTime": {
            "seconds": 1701100800
        },
        "size": 0,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "【Deprecated】sd-turbo",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "stabilityai/sd-turbo"
    },
    {
        "modelId": "17885302502",
        "modelName": "stabilityai/sdxl-turbo",
        "mf": "stabilityai",
        "desc": "SDXL-Turbo 是由 Stability AI 开发的快速生成式文本到图像模型。它是 SDXL 1.0 的蒸馏版本，使用了名为对抗性扩散蒸馏（ADD）的新训练方法。该模型能够在单次网络评估中，基于文本提示合成照片级真实的图像。SDXL-Turbo 可以在 1 到 4 步内以高图像质量进行采样，适用于实时应用研究、生成艺术作品以及在教育或创意工具中的应用。该模型支持非商业和商业用途，主要生成 512x512 像素的图像，但也可以处理更高分辨率",
        "tags": [],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Stability.svg",
        "publishTime": {
            "seconds": 1701014400
        },
        "size": 0,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "【Deprecated】sdxl-turbo",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "stabilityai/sdxl-turbo"
    },
    {
        "modelId": "17885302503",
        "modelName": "ByteDance/SDXL-Lightning",
        "mf": "ByteDance",
        "desc": "SDXL-Lightning 是一个快速文生图模型，能够在几个步骤内生成高质量的 1024px 图像。该模型是从 stabilityai/stable-diffusion-xl-base-1.0 蒸馏而来的。它提供了 1 步、2 步、4 步和 8 步的蒸馏模型检查点。2 步、4 步和 8 步模型的生成质量令人惊叹，而 1 步模型则更具实验性。该模型同时提供完整的 UNet 和 LoRA 检查点，其中完整 UNet 模型具有最佳质量，而 LoRA 模型可应用于其他基础模型",
        "tags": [
            "图生图"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/ByteDance.svg",
        "publishTime": {
            "seconds": 1708444800
        },
        "size": 0,
        "contextLen": 0,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "image",
        "subType": "text-to-image",
        "DisplayName": "【Deprecated】SDXL-Lightning",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 1,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 2,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 3,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 4,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            },
            {
                "Level": 5,
                "RPM": -1,
                "TPM": -1,
                "IPM": 2,
                "IPD": 400
            }
        ],
        "priceUnit": "/ M px / Steps",
        "status": "disable",
        "jsonModeSupport": false,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "ByteDance/SDXL-Lightning"
    },
    {
        "modelId": "17885302504",
        "modelName": "deepseek-ai/deepseek-llm-67b-chat",
        "mf": "deepseek-ai",
        "desc": "DeepSeek LLM 是一个拥有670亿参数的先进语言模型。它在包含2万亿个英文和中文词元的庞大数据集上从零开始训练。deepseek-llm-67b-chat 是在 deepseek-llm-67b-base 基础上通过额外的指令数据微调而来的聊天模型。该模型支持商业用途，并已开源供研究社区使用",
        "tags": [
            "67B",
            "4K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DeepSeek.svg",
        "publishTime": {
            "seconds": 1701187200
        },
        "size": 67,
        "contextLen": 4096,
        "price": "1",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】deepseek-llm-67b-chat",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/deepseek-llm-67b-chat"
    },
    {
        "modelId": "17885302505",
        "modelName": "Qwen/Qwen1.5-14B-Chat",
        "mf": "Qwen",
        "desc": "Qwen1.5-14B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型经过大规模数据预训练，并通过监督微调和直接偏好优化进行后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置等技术，并改进了适用于多种自然语言和代码的分词器。该模型支持 32K 的上下文长度，无需使用 trust_remote_code",
        "tags": [
            "14B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1706630400
        },
        "size": 14,
        "contextLen": 32768,
        "price": "0.7",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Qwen1.5-14B-Chat",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen1.5-14B-Chat"
    },
    {
        "modelId": "17885302508",
        "modelName": "meta-llama/Meta-Llama-3-70B-Instruct",
        "mf": "meta-llama3",
        "desc": "Meta Llama 3 是由 Meta 开发的大型语言模型家族,包括 8B 和 70B 两种参数规模的预训练和指令微调变体。该 70B 指令微调模型针对对话场景进行了优化,在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据,并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3 支持文本生成和代码生成,知识截止日期为 2023 年 12 月",
        "tags": [
            "70B",
            "8K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1713369600
        },
        "size": 70,
        "contextLen": 8192,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3-70B-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "meta-llama/Meta-Llama-3-70B-Instruct"
    },
    {
        "modelId": "17885302509",
        "modelName": "meta-llama/Meta-Llama-3-8B-Instruct",
        "mf": "meta-llama3",
        "desc": "Meta Llama 3 是由 Meta 开发的大型语言模型家族，包括 8B 和 70B 两种参数规模的预训练和指令微调变体。该 8B 指令微调模型针对对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。Llama 3 支持文本生成和代码生成，知识截止日期为 2023 年 3 月",
        "tags": [
            "8B",
            "8K",
            "实名"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Meta.svg",
        "publishTime": {
            "seconds": 1713369600
        },
        "size": 8,
        "contextLen": 8192,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": true,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Meta-Llama-3-8B-Instruct (Free)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "meta-llama/Meta-Llama-3-8B-Instruct"
    },
    {
        "modelId": "17885302512",
        "modelName": "Qwen/Qwen1.5-7B-Chat",
        "mf": "Qwen",
        "desc": "Qwen1.5-7B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置等技术，并改进了适用于多种自然语言和代码的分词器。该 7B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能",
        "tags": [
            "Free",
            "7B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1706630400
        },
        "size": 7,
        "contextLen": 32768,
        "price": "0",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Qwen1.5-7B-Chat (Free)",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 1000,
                "TPM": 50000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen1.5-7B-Chat"
    },
    {
        "modelId": "17885302513",
        "modelName": "Qwen/Qwen1.5-110B-Chat",
        "mf": "Qwen",
        "desc": "Qwen1.5-110B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置、组查询注意力等技术，并改进了适用于多种自然语言和代码的分词器。该 110B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能",
        "tags": [
            "110B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1713974400
        },
        "size": 110,
        "contextLen": 32768,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Qwen1.5-110B-Chat",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen1.5-110B-Chat"
    },
    {
        "modelId": "17885302514",
        "modelName": "Qwen/Qwen1.5-32B-Chat",
        "mf": "Qwen",
        "desc": "Qwen1.5-32B-Chat 是 Qwen2 的 beta 版本，是一个基于 Transformer 架构的 decoder-only 语言模型。该模型在大规模数据上进行了预训练，并通过监督微调和直接偏好优化进行了后训练。它采用了 SwiGLU 激活函数、注意力 QKV 偏置、组查询注意力等技术，并改进了适用于多种自然语言和代码的分词器。该 32B 模型支持 32K 的上下文长度，无需使用 trust_remote_code，并在对话模型方面显著提升了人类偏好性能",
        "tags": [
            "32B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1712160000
        },
        "size": 32,
        "contextLen": 32768,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "【Deprecated】Qwen1.5-32B-Chat",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 60000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 160000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 2000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": false,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen1.5-32B-Chat"
    },
    {
        "modelId": "17885302520",
        "modelName": "deepseek-ai/DeepSeek-V2-Chat",
        "mf": "deepseek-ai",
        "desc": "DeepSeek-V2 是一个强大、经济高效的混合专家（MoE）语言模型。它在 8.1 万亿个 token 的高质量语料库上进行了预训练，并通过监督微调（SFT）和强化学习（RL）进一步提升了模型能力。与 DeepSeek 67B 相比， DeepSeek-V2 在性能更强的同时，节省了 42.5% 的训练成本，减少了 93.3% 的 KV 缓存，并将最大生成吞吐量提高到了 5.76 倍。该模型支持 128k 的上下文长度，在标准基准测试和开放式生成评估中都表现出色",
        "tags": [
            "MoE",
            "236B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/DeepSeek.svg",
        "publishTime": {
            "seconds": 1714924800
        },
        "size": -1,
        "contextLen": 32768,
        "price": "1.33",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "DeepSeek-V2-Chat",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 10000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 15000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 125000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 500000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "deepseek-ai/DeepSeek-V2-Chat"
    },
    {
        "modelId": "17885302523",
        "modelName": "Qwen/Qwen2-72B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-72B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 72B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力",
        "tags": [
            "72B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1716825600
        },
        "size": 72,
        "contextLen": 32768,
        "price": "4.13",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-72B-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-72B-Instruct"
    },
    {
        "modelId": "17885302525",
        "modelName": "Qwen/Qwen2-57B-A14B-Instruct",
        "mf": "Qwen2",
        "desc": "Qwen2-57B-A14B-Instruct 是 Qwen2 系列中的指令微调大语言模型，采用混合专家（Mixture-of-Experts）架构，总参数量为 57B，激活参数为 14B。该模型基于 Transformer 架构，使用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中，该模型表现出色，超越了大多数开源模型，并在某些任务上展现出与专有模型相当的竞争力",
        "tags": [
            "MoE",
            "57B",
            "32K"
        ],
        "icon": "https://sf-maas-uat-prod.oss-cn-shanghai.aliyuncs.com/Model_LOGO/Tongyi.svg",
        "publishTime": {
            "seconds": 1717430400
        },
        "size": -1,
        "contextLen": 32768,
        "price": "1.26",
        "currency": "¥",
        "operationLabel": [],
        "needAuth": false,
        "onlineDemo": false,
        "type": "text",
        "subType": "chat",
        "DisplayName": "Qwen2-57B-A14B-Instruct",
        "sort": 2,
        "sameSeries": [],
        "language": [],
        "modelInfo": [
            {
                "Level": 0,
                "RPM": 1000,
                "TPM": 20000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 1,
                "RPM": 1200,
                "TPM": 30000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 2,
                "RPM": 2000,
                "TPM": 40000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 3,
                "RPM": 4000,
                "TPM": 80000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 4,
                "RPM": 8000,
                "TPM": 250000,
                "IPM": -1,
                "IPD": -1
            },
            {
                "Level": 5,
                "RPM": 10000,
                "TPM": 1000000,
                "IPM": -1,
                "IPD": -1
            }
        ],
        "priceUnit": "/ M Tokens",
        "status": "disable",
        "jsonModeSupport": true,
        "functionCallSupport": false,
        "fimCompletionSupport": false,
        "chatPrefixCompletionSupport": true,
        "vlm": false,
        "onlyByChargeBalance": false,
        "supportFT": false,
        "targetModelName": "Qwen/Qwen2-57B-A14B-Instruct"
    }
]